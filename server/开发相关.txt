protobuf
https://www.cnblogs.com/liugh/p/7505533.html
google_protobuf数据类型
https://blog.csdn.net/superbfly/article/details/17920383
protobuf repeated类型的使用
https://blog.csdn.net/ve12345/article/details/84529672


其是用 java nio 自己实现了，
那个 hadoop 协议是如何来做的？

1.网络传输，直接用 protobuf 行不，
2.用类名，
HBaseNetProtocol
{
	className:"getRegion",
	content:"asdfasdfasdf"
}


因此，我可以使用一个简单的定长网络读取协议即可，
netty中是否已经有了这种简单的读取的东东，应该也是用，可是用 nio 的话，
用进 netty, 看能否成功，
天然支持 Google Protobuf,

com.hbasetest.proto.HBaseNetProtocol

有个中心节点,用多线程的方式,

1.用指定 master 的方式，在启动时，添加 master 参数,
2.slave节点，在启动时，添加 slave 参数,
3.启动后,写入 zookeeper,


客户端,
1.客户端发送读请求，拼成 sql 语句,(先写死用字符串来传递数据)
2.服务端使用 master-slave 架构来实现，
2.1.如果只是简单的根据主键，访问某个分区中的数据，则 master,可进行解析，返回这张表所在的 slave 的位置(ip地址)和 key 范围，
2.2.客户端取得 slave 的位置(ip地址),像相应的 slave, 发送 sql 语句, slave 去拉取数据即可。

3.但是查询通常不简单,sql 语句通常会关联表,
3.1.
select a.*,b.* from tableA a, table b
where a.id>1
and a.id < 1000
and a.b_id=b.id

3.2.假设都在 master 上来执行了,master 用 nest loop 来完成这些操作,每 100 条输出一次，避免占用大量内存。

服务端 master-slave 的落地实现,
1.用指定 master 的方式，在启动时，添加 master 参数,
    1.1.实现成直接运行 HMaster 的方式,
    java HMaster
2.slave节点，在启动时，添加 slave 参数,
    java RegionServer,
3.启动后,写入 zookeeper,

1.客户端传给服务端 sql 语句的落地实现,
1.1.即 Google Protobuf 的落地实现,        running,---------------------------,
1.1.1. sql 语句的协议实现,
HBaseSqlProtocol
{
	sql:"select * from testA where id=?"
	parameter:[{
	    type:1,     0:byte,1:short,2:int,3:long,4:float,5:double,6:char,7:boolean,8:date,9:time,10:datetime,
	    value: xx,
	},{
        type:1,
        value: xx,
    }]
}


object 的赋值会比较的复杂,
1.1.2. 服务端的 protobuf 的落地实现,         running,---------------------------,
    wwww,是否要用到 netty? 用 netty 来传递,用线程来启动这个东东,
1.1.3. 客户端的 protobuf 的落地实现,

1.2. 如何把 H2 的实现给拷贝弄进来,




